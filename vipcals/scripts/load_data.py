import numpy as np
import os
import math
import pandas as pd
import pkg_resources

import functools
print = functools.partial(print, flush=True)

from astropy.io import fits
from astropy.table import Table
from astropy.coordinates import SkyCoord
from astropy.coordinates import search_around_sky
from astropy import units as u

from scripts.helper import Source

from AIPSData import AIPSUVData
from AIPSTask import AIPSTask, AIPSList
AIPSTask.msgkill = -8


def set_name(path, source, klass):
    """Set the name that will be used for the all the ouputs.

    Name format is SOURCENAME_PROJECT_BAND_DATE

    :param path: path to the uvfits/idifits file
    :type path: str
    :param source: name of the science target
    :type source: str
    :param klass: klass name in AIPS, contains the band information
    :type klass: str
    :return: name to be used in the outputs
    :rtype: str
    """    
    hdul = fits.open(path)
    obs = hdul['UV_DATA'].header['OBSCODE'].strip()
    if '/' in hdul['UV_DATA'].header['DATE-OBS']:
        date = hdul['UV_DATA'].header['DATE-OBS'].split('/')
        if int(date[2]) > 90:
            date_obs = '19' + date[2] + '-' + date[1] + '-' + date[0]
        else:
            date_obs = '20' + date[2] + '-' + date[1] + '-' + date[0]
    if '-' in hdul['UV_DATA'].header['DATE-OBS']:
        date_obs = hdul['UV_DATA'].header['DATE-OBS']
    hdul.close()
    freq = int(klass.strip('G'))

    name = source + '_' + obs + '_' + klass + '_' + date_obs
    return(name)

def get_source_list(file_path_list, freq = 0):
    """Get a source list from a uvfits/idifits file.

    :param file_path_list: list of paths of the uvfits/idifts files
    :type file_path_list: list of str
    :param freq: if there are multiple frequency ids, which one to choose; defaults to 0
    :type freq: int, optional
    :return: list of sources contained in the file
    :rtype: list of :class:`~vipcals.scripts.helper.Source` objects
    """    
    full_source_list = []
    for file_path in file_path_list:
        hdul = fits.open(file_path)
        for elements in Table(hdul['SOURCE'].data):
            a = Source()
            a.name = elements['SOURCE'].strip()
            try:
                a.ra = elements['RAOBS']
                a.dec = elements['DECOBS']
            except KeyError:
                a.ra = elements['RAEPO']
                a.dec = elements['DECEPO']
            try:
                a.id = elements['ID_NO.']
            except KeyError:
                a.id = elements['SOURCE_ID']
            # Frequency can be given as an input when multiple bands
            if freq != 0:
                a.restfreq = freq
            # If not, grab it from the header
            else:
                a.restfreq = hdul['FREQUENCY'].header['REF_FREQ']
 
            a.set_band()      

            # Check if the source was already on the list (multiple files)
            if a.name not in [s.name for s in full_source_list]:
                full_source_list.append(a)
                
            a = None  
        hdul.close()      
        
    # Make sure that source names are ASCII characters
    for s in full_source_list:
        name_string = s.name
        s.name = name_string.split('\x00', 1)[0]

        
    return(full_source_list)

def redo_source_list(uvdata):
    """Create again the source list after loading the data.

    This is done to avoid problems with the source IDs after 
    concatenating multiple files.

    :param data: visibility data
    :type data: AIPSUVData
    :return: list of sources contained in the observations
    :rtype: list of :class:`~vipcals.scripts.helper.Source` objects
    """    
    su_table = uvdata.table('SU', 1)
    full_source_list = []
    for source in su_table:
        b = Source()
        b.name = source['source'].replace(" ", "")
        b.id = source['id__no']
        freq_indx = uvdata.header['ctype'].index('FREQ')
        b.restfreq = uvdata.header['crval'][freq_indx]

        b.set_band()

        full_source_list.append(b)
        b= None

    return full_source_list

def find_calibrators(full_source_list, choose = 'BYCOORD'):
    """Choose possible calibrators from a source list.

    It loads information of ~ 9000 sources from an external file.
    Then, checks if there is available flux information for the
    sources in the source list generated by the 
    :func:`~vipcals.scripts.load_data.get_source_list` function. If there are more 
    than 3 observed sources, the names of the brightest 3 are given in return. If not, 
    all sources are returned.

    :param full_source_list: list of sources contained in the file
    :type full_source_list: list of :class:`~vipcals.scripts.helper.Source` objects
    :param choose: cross-match the sources using names ("BYNAME") or coordinates 
    ("BYCOORD"); default "BYCOORD"
    :type choose: str 
    :return: names of possible calibrators available in the file
    :rtype: list of str
    """    
    col_names = ['NameJ2000', 'NameB1950', 'NameICRF3', 'NameOther','RA',\
                 'DEC', 'RAE', 'DECE', 'S_short', 'S_long', 'C_short',\
                 'C_long', 'X_short', 'X_long', 'U_short', 'U_long',\
                 'K_short', 'K_long', 'Ka', 'Ref']

    catalogue_path = \
        pkg_resources.resource_filename(__name__,\
                                         '../catalogues/vlbaCalib_allfreq_full.txt')
    
    calib_list = pd.read_fwf(catalogue_path, skiprows = 16,\
                             names = col_names)

    # Crossmatch using coordinates (fast, needs astropy)
    if choose == "BYCOORD":
        source_coords = SkyCoord([x.ra for x in full_source_list], \
                             [y.dec for y in full_source_list], unit = 'deg')
        calib_coords = SkyCoord(calib_list['RA'].to_list(), calib_list['DEC'].to_list())
        idx1, idx2 ,_ ,_ = search_around_sky(source_coords, calib_coords, 5 * u.arcsec)
        for i, idx in enumerate(idx1):
            try:
                full_source_list[idx].band_flux = \
                    float(calib_list.iloc[idx2[i]][full_source_list[idx].band + '_short'])
            except:
                full_source_list[idx].band_flux = np.NaN

    # Crossmatch using names (slow, might fail)
    if choose == "BYNAME":
        for elements in full_source_list:
            row = calib_list.loc[calib_list.isin([elements.name]).any(axis=1)]
            try:
                elements.band_flux = float(row.iloc[0][elements.band + '_short'])
            except:
                elements.band_flux = np.NaN
        
    full_source_list.sort(key = lambda x: 0 if math.isnan(x.band_flux)\
                          else x.band_flux, reverse = True)
    
    # If none of the sources is on the calibrator list, load all
    if np.isnan(full_source_list[0].band_flux) == True:
        raise ValueError("None of the sources was found on the VLBA calibrator list.")

    if len(full_source_list) > 3:
        return [str(full_source_list[0].name),str(full_source_list[1].name),\
                str(full_source_list[2].name)]
            
    # If there are 3 or less sources just load all 
    else:
        calibs = []
        for src in full_source_list:
            calibs.append(src.name)
        return(calibs)
    
def is_it_multifreq_id(file_path_list):
    """Check if the files contains multiple bands splitted in IDs.

    If more than one file is given, check how many files have common frequencies, and 
    return a dictionary specifying which frequency corresponds to which files.

    :param file_path: path of the uvfits/idifts file
    :type file_path: str
    :return: whether the dataset has multiple bands, list of frequencies, dictionary 
        with each file and which frequencies it covers
    :rtype: boolean, int, list of float
    """    
    multifreq = False
    file_dict = {}
    id_list = []
    for file in file_path_list:
        with fits.open(file) as hdul:
            if len(hdul['FREQUENCY'].data['FREQID']) > 1:
                multifreq = True
            file_dict[file] = []
            for i in range(len(hdul['FREQUENCY'].data['FREQID'])):
                id = hdul['FREQUENCY'].data['FREQID']
                freq = np.floor(hdul['SOURCE'].data['RESTFREQ'][0] \
                                + hdul['FREQUENCY'].data['BANDFREQ'][i])
                if type(freq) == np.float64: # Single IF
                    file_dict[file].append((freq))
                    id_list.append((freq))
                else:
                    file_dict[file].append((tuple(freq)))
                    id_list.append((tuple(freq)))
                    
    id_list = list(set(id_list))

    return(multifreq, id_list, file_dict)

def group_ids(id):
    """Look for multiple frequencies within one frequency ID.
    
    Reads an id from :func:`~vipcals.scripts.load_data.is_it_multifreq_id` and 
    returns groups with parameters useful for the main workflow to deal with different 
    frequencies. 

    Args:
    :param id: _description_

    :return: minimum frequency of the id, minimum frequency of the group, minimum and 
        maximum IFs containing the group
    :rtype: float, float, list of int
    """    
    if not isinstance(id, np.float64):
        # Sort values
        # NOT SURE OF THE SORTING STEP, STILL TESTING
        sorted_values = sorted(id)
        #sorted_values = id
        # Group based on jumps > 1e9 using positions in the sorted list
        groups = []
        current_group = [0]

        for i in range(1, len(sorted_values)):
            if sorted_values[i] - sorted_values[i - 1] > 1e9:
                groups.append(current_group)
                current_group = [i]
            else:
                current_group.append(i)
        groups.append(current_group)

        # Get overall minimum
        overall_min = min(id)

        # Create the output list
        result = []
        for group in groups:
            group_min = min(sorted_values[i] for i in group)
            result.append((group_min, overall_min, [min(group), max(group)]))

        return result
    
    else:
        return( [(id, id, [0,0] )])

def group_ids_v2(id):
    if isinstance(id, np.float64):
        return [(id, id, [0, 0])]
    # Ensure input is a list or array
    id = list(id)
    groups = []
    current_group = [0]
    for i in range(1, len(id)):
        if abs(id[i] - id[i - 1]) > 1e9:
            groups.append(current_group)
            current_group = [i]
        else:
            current_group.append(i)
    groups.append(current_group)
    overall_min = min(id)
    result = []
    for group in groups:
        group_min = min(id[i] for i in group)
        result.append((group_min, overall_min, [min(group), max(group)]))
    return result
    
def are_sources_in_id(file_path_list, loaded_id, sources):
    """_summary_

    Args:
        file_path_list (_type_): _description_
        id (_type_): _description_
        sources (_type_): _description_
    """   
    missingso = [] 
    with fits.open(file_path_list[0]) as hdul:
        # Get sources_id
        if type(hdul['SOURCE'].data['SOURCE'][0]) == str: 
            sources_id = [x['ID_NO.'] for x in hdul['SOURCE'].data 
                        if x['SOURCE'].split('\x00', 1)[0].strip() in sources]
        else:
            sources_id = [x['ID_NO.'] for x in hdul['SOURCE'].data 
                      if x['SOURCE'].decode('latin-1', errors='ignore').split('\x00', 1)[0].strip() in sources]
        
        for i in range(len(hdul['FREQUENCY'].data['FREQID'])):
            fid = hdul['FREQUENCY'].data['FREQID'][i]
            freq = np.floor(hdul['SOURCE'].data['RESTFREQ'][0] \
                            + hdul['FREQUENCY'].data['BANDFREQ'][i])

            if np.all(freq == np.array(loaded_id)):
                for sid in sources_id:
                    uv_data = hdul['UV_DATA'].data
                    exists = np.any((uv_data['SOURCE'] == sid) & (uv_data['FREQID'] == fid)) 
                    if exists == False:
                        if type(hdul['SOURCE'].data['SOURCE'][0]) == str: 
                            missingso = [x['SOURCE'].split('\x00', 1)[0].strip() for x in hdul['SOURCE'].data 
                                        if x['ID_NO.'] == sid]
                        else:
                            missingso = [x['SOURCE'].decode('latin-1', errors='ignore').split('\x00', 1)[0].strip() for x in hdul['SOURCE'].data 
                                        if x['ID_NO.'] == sid]                            
                        break

    return(missingso)

def is_it_multifreq_if(file_path):
    """Check if the file contains multiple bands splitted in IFs.
    
    Looks at the central frequency of all IFs and looks for jumps of
    more than 1 GHz between them. Only works for datasets with 1 or 2
    frequency bands, not more.

    :param file_path: path of the uvfits/idifts file
    :type file_path: str
    :return: True if the dataset has multiple bands, False if not; Value of the first \
             IF, always 1; value of the last IF of band 1; value of the first IF of \
             band 2; value of the last IF of band 2; first digit of the frequency of \
             band 1; first digit of the frequency of band 2; frequency of band 1 ;\
             frequency of band 2
    :rtype: boolean, int, int, int, int, str, str, float, float
    """    
    multifreq = False
    hdul = fits.open(file_path)
    if_freq = hdul['FREQUENCY'].header['REF_FREQ'] \
              + hdul['FREQUENCY'].data['BANDFREQ']

    if isinstance(if_freq[0], np.float64) == True:
        # Data is single IF
        if if_freq[0] > 1e10:
            freq = str(if_freq[0])[:2] 
        else:
            freq = str(if_freq[0])[:1] 
        return(False, 1, 1, 1, 1, freq, freq)
               
    for IF,freq in enumerate(if_freq[0]):
        if IF == 0:
            continue
        if abs(freq - if_freq[0][IF-1]) > 1e9 :
            multifreq = True
            break
    freq_1 = np.floor(if_freq[0][0])
    freq_2 = np.floor(if_freq[0][-1])

    if freq_1 > 1e10:
        klass_1 = str(freq_1)[:2]
    else:
        klass_1 = str(freq_1)[0]
    if freq_2 > 1e10:
        klass_2 = str(freq_2)[:2]
    else:
        klass_2 = str(freq_2)[0]

    hdul.close()

    return(multifreq, 1, IF, IF+1, len(if_freq[0]), klass_1,\
           klass_2, freq_1, freq_2)
        

def load_data(file_path_list, name, sources, disk, multi_id, selfreq, klass = '', \
              seq = 1, bif = 0, eif = 0, l_a = False, 
              symlink_path = os.path.expanduser("~/.vipcals/tmp")):
    """Load data from a uvfits/idifits file.

    :param file_path_list: list of paths of the uvfits/idifts files
    :type file_path_list: list of str
    :param name: file name whithin AIPS
    :type name: str
    :param sources: list of sources to load
    :type sources: list of str
    :param disk: disk number whithin AIPS
    :type disk: int
    :param multi_id: True if there are multiple frequency ids, False otherwise
    :type multi_id: bool
    :param selfreq: if there are multiple frequency ids, which one to load
    :type selfreq: int
    :param klass: class name whithin AIPS; defaults to ''
    :type klass: str, optional
    :param seq: sequence number within AIPS; defaults to 1
    :type seq: int, optional
    :param bif: first IF to copy, 0 => 1; defaults to 0
    :type bif: int, optional
    :param eif: highest IF to copy,  0 => all higher than bif; defaults to 0
    :type eif: int, optional
    :param l_a: load all sources; default False
    :type l_a: bool, optional
    :param symlink_path: path where to create the symbolic links needed to load the data;
        default is the /vipcals/tmp folder
    :type symlink_path: str, optional
    """      
    fitld = AIPSTask('fitld')
    # Create symbolic links for each of the files
    # This is necessary when multiple files need to be concatenated
    # Delete any if they already exist
    if os.path.exists(symlink_path + '/aux_1'):
        os.system('rm ' + symlink_path + '/aux_*')
    for n, filepath in enumerate(file_path_list):
        os.system('ln -s ' + filepath + ' ' + symlink_path + '/aux_' + str(n+1))
    

    fitld.ncount = int(len(file_path_list))  
    if len(file_path_list) > 1:
        fitld.doconcat = 1 
    fitld.outname = name
    fitld.outdisk = disk
    fitld.outclass = klass
    fitld.outseq = seq

    # If the data already exists in AIPS, delete it
    uvdata = AIPSUVData(name, klass, disk, seq)
    if uvdata.exists() == True:
        uvdata.zap()
    
    if l_a == False:
        fitld.sources = AIPSList(sources)
    fitld.bif = bif
    fitld.eif = eif
    fitld.clint = 0.1

    if multi_id == True:
        fitld.selfreq = float(selfreq)  
        # Set tolerance as 0.5% of the selected frequency
        fitld.fqtol = float(selfreq) * 5

    fitld.datain = symlink_path + '/aux_'

    fitld.go()
    # Remove the symbolic links
    os.system('rm ' + symlink_path + '/aux_*')

    # If multiple files, merge redundant information in tables
    if len(file_path_list) > 1:
        merge_red_tables(AIPSUVData(name, klass, disk, seq)) 


def merge_red_tables(data, timetol = 0.1):
    """Merge redundant information on GC, TY, and PC tables.

    Uses the TAMRG task in AIPS to merge tables when loading multiple files.
    Inputs for the task are copied from the MERGECAL procedure

    :param data: visibility data
    :type data: AIPSUVData
    :param timetol: tolerance for comparing times in seconds; defaults to 0.1
    :type timetol: float, optional
    """    


    # If multiple files, merge redundant data in tables
    # Inputs are copied from RUN MERGECAL procedure
    if 'GC' in data.tables:
        # Process GC tables
        tamrg = AIPSTask('tamrg')
        tamrg.inname = data.name
        tamrg.inseq = data.seq
        tamrg.inclass = data.klass
        tamrg.indisk = data.disk

        tamrg.inext = 'GC'
        tamrg.aparm = AIPSList([1,1,2,1,3,1])
        tamrg.bparm = AIPSList([1,2,3])

        tamrg.invers = 1
        tamrg.outvers = 1

        tamrg.go()

    if 'TY' in data.tables:
        # Process TY tables
        tamrg = AIPSTask('tamrg')
        tamrg.inname = data.name
        tamrg.inseq = data.seq
        tamrg.inclass = data.klass
        tamrg.indisk = data.disk

        tamrg.inext = 'TY'
        tamrg.aparm = AIPSList([1,1,4,1,5,1,6,1])
        tamrg.bparm = AIPSList([1,3,4,5,6])
        tamrg.cparm = AIPSList([timetol / (24.0 * 60.0 * 60.0), 0])

        tamrg.invers = 1
        tamrg.outvers = 1

        tamrg.go()

    if 'PC' in data.tables:
        # Process PC tables
        tamrg = AIPSTask('tamrg')
        tamrg.inname = data.name
        tamrg.inseq = data.seq
        tamrg.inclass = data.klass
        tamrg.indisk = data.disk

        tamrg.inext = 'PC'
        tamrg.aparm = AIPSList([1,1,4,1,5,1,6,1])
        tamrg.bparm = AIPSList([1,3,4,5,6])
        tamrg.cparm = AIPSList([timetol / (24.0 * 60.0 * 60.0), 0])

        tamrg.invers = 1
        tamrg.outvers = 1

        tamrg.go()

def print_listr(data, path_list, filename_list):
    """Print scan information in an external file.

    Runs the FITLD task in AIPS and prints the output in _scansum.txt

    :param data: visibility data
    :type data: AIPSUVData
    :param path_list: list of filepaths for each source
    :type path_list: list of str
    :param filename_list: list of folder names for the different science targets
    :type filename_list: list of str
    """    
    listr = AIPSTask('listr')
    listr.inname = data.name
    listr.inclass = data.klass
    listr.indisk = data.disk
    listr.inseq = data.seq
    
    listr.optype = 'SCAN'
    listr.flagver = 1
    listr.xinc = 1
    listr.docrt = -2
    for i, name in enumerate(filename_list):
        listr.outprint = path_list[i] + '/' + name + '_scansum.txt'
        
        listr.go()

def time_aver(data, oldtime, newtime):
    """Average visibility data in time

    Creates a new entry in AIPS adding '_AT' to the name

    :param data: visibility data
    :type data: AIPSUVData
    :param oldtime: previous time resolution in seconds
    :type oldtime: float
    :param newtime: new time resolution in seconds
    :type newtime: float
    """    
    uvavg = AIPSTask('uvavg')
    uvavg.inname = data.name
    uvavg.inclass = data.klass
    uvavg.indisk = data.disk
    uvavg.inseq = data.seq

    uvavg.doacor = 1
    uvavg.yinc = newtime
    uvavg.zinc = oldtime
    uvavg.opcode = 'TIME'
    
    uvavg.outname = data.name[:9] + '_AT'
    uvavg.outclass = data.klass
    uvavg.outdisk = data.disk
    uvavg.outseq = data.seq
    
    uvavg.go()
    
def freq_aver(data, ratio):
    """Average visibility data in frequency

    Creates a new entry in AIPS adding '_AF' or '_ATF' to the name if it has 
    already been averaged in time.

    :param data: visibility data
    :type data: AIPSUVData
    :param ratio: ratio between the old number of frequency channels and the new one, \
    e.g. when going from 64 channels to 16, this number is 4 
    :type ratio: float
    """    
    avspc = AIPSTask('avspc')
    avspc.inname = data.name
    avspc.inclass = data.klass
    avspc.indisk = data.disk
    avspc.inseq = data.seq

    avspc.doacor = 1
    avspc.channel = ratio
    avspc.avoption = 'SUBS'

    if data.name[-3:] == '_AT':
        avspc.outname = data.name[:-3] + '_ATF'
    else:
        avspc.outname = data.name[:9] + '_AF'
    avspc.outclass = data.klass
    avspc.outdisk = data.disk
    avspc.outseq = data.seq

    avspc.go()

def run_indxr(data):
    """Creates an index (NX) table and indexes the uv data file.

    Also creates CL#1 with entries every 0.1 minutes.

    :param data: visibility data
    :type data: AIPSUVData
    """    
    indxr = AIPSTask('indxr')
    indxr.inname = data.name
    indxr.inclass = data.klass
    indxr.indisk = data.disk
    indxr.inseq = data.seq
    
    indxr.cparm[3] = 0.1  # Create CL#1
    indxr.cparm[4] = 1    # Recalculate CL entry group delays using IM table
    
    indxr.go()

def tborder(data, log):
    """Sort data in Time - Baseline order (TB)

    :param data: visibility data
    :type data: AIPSUVData
    """    
    
    uvsrt = AIPSTask('uvsrt')
    uvsrt.inname = data.name
    uvsrt.inclass = data.klass
    uvsrt.indisk = data.disk
    uvsrt.inseq = data.seq
    uvsrt.outname = data.name
    uvsrt.outclass = data.klass
    uvsrt.outdisk = data.disk
    uvsrt.outseq = data.seq
    
    uvsrt.sort = 'TB'
            
    uvsrt.go()